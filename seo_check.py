#!/usr/bin/env python3
"""
SEO å¥åº·æ£€æŸ¥è„šæœ¬
æ£€æŸ¥æ‰€æœ‰ HTML é¡µé¢çš„ SEO é…ç½®æ˜¯å¦å®Œæ•´
"""

import os
import re
from pathlib import Path
from bs4 import BeautifulSoup
import json

def check_seo_tags(html_path):
    """æ£€æŸ¥å•ä¸ª HTML æ–‡ä»¶çš„ SEO æ ‡ç­¾"""
    try:
        with open(html_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        soup = BeautifulSoup(content, 'html.parser')
        
        # å¿…éœ€çš„ SEO æ ‡ç­¾
        required_tags = {
            'title': soup.find('title'),
            'description': soup.find('meta', attrs={'name': 'description'}),
            'keywords': soup.find('meta', attrs={'name': 'keywords'}),
            'og:title': soup.find('meta', attrs={'property': 'og:title'}),
            'og:description': soup.find('meta', attrs={'property': 'og:description'}),
            'og:url': soup.find('meta', attrs={'property': 'og:url'}),
            'canonical': soup.find('link', attrs={'rel': 'canonical'}),
            'robots': soup.find('meta', attrs={'name': 'robots'}),
        }
        
        results = {}
        for tag_name, tag in required_tags.items():
            if tag:
                if tag.name == 'title':
                    content = tag.string
                elif tag.name == 'link':
                    content = tag.get('href', '')
                else:
                    content = tag.get('content', '')
                
                results[tag_name] = {
                    'present': True,
                    'content': content[:100] if content else '',
                    'length': len(content) if content else 0
                }
            else:
                results[tag_name] = {'present': False}
        
        return results
    except Exception as e:
        return {'error': str(e)}

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ” SEO å¥åº·æ£€æŸ¥å¼€å§‹...")
    print("=" * 80)
    
    # æŸ¥æ‰¾æ‰€æœ‰ HTML æ–‡ä»¶
    html_files = []
    
    # æ ¹ç›®å½•çš„ HTML æ–‡ä»¶
    for file in Path('.').glob('*.html'):
        html_files.append(str(file))
    
    # å­ç›®å½•çš„ index.html
    for subdir in ['ielts', 'F2English25']:
        index_file = Path(subdir) / 'index.html'
        if index_file.exists():
            html_files.append(str(index_file))
    
    html_files.sort()
    
    # æ£€æŸ¥æ¯ä¸ªæ–‡ä»¶
    all_passed = True
    issues = []
    
    for html_file in html_files:
        print(f"\nğŸ“„ æ£€æŸ¥: {html_file}")
        results = check_seo_tags(html_file)
        
        if 'error' in results:
            print(f"   âŒ é”™è¯¯: {results['error']}")
            all_passed = False
            issues.append(f"{html_file}: {results['error']}")
            continue
        
        # æ£€æŸ¥å¿…éœ€æ ‡ç­¾
        missing = []
        warnings = []
        
        for tag_name, result in results.items():
            if not result.get('present', False):
                missing.append(tag_name)
            elif tag_name == 'description' and result.get('length', 0) < 50:
                warnings.append(f"{tag_name} å¤ªçŸ­ ({result.get('length')} å­—ç¬¦)")
            elif tag_name == 'title' and result.get('length', 0) < 20:
                warnings.append(f"{tag_name} å¤ªçŸ­ ({result.get('length')} å­—ç¬¦)")
        
        if missing:
            print(f"   âŒ ç¼ºå°‘æ ‡ç­¾: {', '.join(missing)}")
            all_passed = False
            issues.append(f"{html_file}: ç¼ºå°‘ {', '.join(missing)}")
        elif warnings:
            print(f"   âš ï¸  è­¦å‘Š: {'; '.join(warnings)}")
        else:
            print(f"   âœ… æ‰€æœ‰ SEO æ ‡ç­¾å®Œæ•´")
    
    print("\n" + "=" * 80)
    
    if all_passed:
        print("âœ… SEO å¥åº·æ£€æŸ¥é€šè¿‡ï¼æ‰€æœ‰é¡µé¢éƒ½æœ‰å®Œæ•´çš„ SEO æ ‡ç­¾ã€‚")
    else:
        print("âŒ SEO å¥åº·æ£€æŸ¥å‘ç°é—®é¢˜ï¼š")
        for issue in issues:
            print(f"   - {issue}")
    
    print(f"\nğŸ“Š ç»Ÿè®¡: æ£€æŸ¥äº† {len(html_files)} ä¸ª HTML æ–‡ä»¶")
    
    return 0 if all_passed else 1

if __name__ == '__main__':
    exit(main())
